{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94daf52e-a830-40b5-8fbc-8ca5b5e945e1",
   "metadata": {},
   "source": [
    "# Histology Dataset attempt one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69631a9-e8a9-4e83-8316-ed53e937c402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import kornia as K\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "\n",
    "import import_ipynb \n",
    "import dl_helper\n",
    "print(dl_helper.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f77c9e-a614-46f3-83f8-3559fcd13491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_histo_from_path(path):\n",
    "    print(f\"read from {path}\")\n",
    "    names = []\n",
    "    labels = []\n",
    "    for i in os.listdir(path):\n",
    "        tmp = os.listdir(path+'/'+i)\n",
    "        names.extend(tmp)\n",
    "        labels.extend([i] * len(tmp))\n",
    "    data = []\n",
    "    new_labels = []\n",
    "    for i, name in enumerate(names):\n",
    "        print(f\"{i+1}/{len(names)}      \", end=\"\\r\")\n",
    "        read = Image.open(f\"{path}/{labels[i]}/{name}\")\n",
    "        if read.size == (50, 50) and read.mode == 'RGB':\n",
    "            # data.append(rgb2gray(read))\n",
    "            tmp = TF.to_tensor(read)\n",
    "            data.append(tmp.reshape(1, *tmp.shape))\n",
    "            new_labels.append(int(labels[i][0]))\n",
    "    data = torch.cat(data)\n",
    "    labels = torch.tensor(new_labels)\n",
    "    print('')\n",
    "    return data, labels\n",
    "\n",
    "def read_img(path='/train'):\n",
    "    path = \"../data/Breast Histopathology Images SMALL\"+path\n",
    "    x, y = read_histo_from_path(path)\n",
    "    # return reshape(x), y\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def read_histo_small():\n",
    "    path = \"../data/Breast Histopathology Images SMALL\"\n",
    "    train_path = path+'/train'\n",
    "    val_path = path+'/valid'\n",
    "    test_path = path+'/test'\n",
    "    x_train, y_train = read_histo_from_path(train_path)\n",
    "    x_val, y_val = read_histo_from_path(val_path)\n",
    "    x_test, y_test = read_histo_from_path(test_path)\n",
    "    # return reshape(x_train), y_train, reshape(x_val), y_val,reshape(x_test), y_test\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "def reshape(x):\n",
    "    return x.permute(0,3,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ceb63f0-f4e9-4faf-b126-f2c2e63684c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read from ../data/Breast Histopathology Images SMALL/train\n",
      "14550/19426      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_386256/711439203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_386256/2052441348.py\u001b[0m in \u001b[0;36mread_img\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/Breast Histopathology Images SMALL\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_histo_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m# return reshape(x), y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_386256/2052441348.py\u001b[0m in \u001b[0;36mread_histo_from_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# data.append(rgb2gray(read))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mnew_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pDL/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I;16'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     img = torch.from_numpy(\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pDL/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mArrayData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pDL/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pDL/lib/python3.8/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train, y_train = read_img('/train') \n",
    "x_val, y_val = read_img('/valid')\n",
    "x_test, y_test = read_img('/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9af49-dfd0-411c-9a57-5c2914995a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0].permute(1,2,0), cmap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84760262-fb58-4fc6-bd54-386996406b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ea6b0-a378-4ffa-88e5-145aab4cf14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from here https://stackoverflow.com/a/58748125/1983544\n",
    "num_workers = os.cpu_count() \n",
    "if 'sched_getaffinity' in dir(os):\n",
    "    num_workers = len(os.sched_getaffinity(0))\n",
    "print (num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c51204-8e2e-4917-ae18-9defb195ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(list(zip(x_train, y_train)),\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers = num_workers)\n",
    "valid_dataloader = DataLoader(list(zip(x_val, y_val)),\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False,\n",
    "                              drop_last=False,\n",
    "                              num_workers = num_workers)\n",
    "test_dataloader = DataLoader(x_test,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             drop_last=False,\n",
    "                             num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac82206-c17f-4c4c-bf24-3b20751ce6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "lambda_l2 = 1e-4\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7df935-d74d-4b8a-ad8f-d6f8381f6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2cd087-3a75-45bd-b885-2bd651addc62",
   "metadata": {},
   "source": [
    "## Resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e840326-d25a-4cdb-acc5-78a4d6ae9a62",
   "metadata": {},
   "source": [
    "### Not pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e61b6-cebb-4987-97ab-84fbb7b6fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_18_ut = timm.create_model('resnet18', pretrained=False, num_classes=2)\n",
    "print(model_18_ut.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32204c0d-539b-4339-a512-14487902b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_18_ut.fc.parameters(),\n",
    "                             lr=learning_rate,\n",
    "                             eps=1e-2,\n",
    "                             weight_decay=lambda_l2)  # built-in L2\n",
    "\n",
    "epochs = EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb76735-0653-4137-8f0a-543e2b7e7868",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_18_ut = dl_helper.train_epochs(train_dataloader, valid_dataloader, model_18_ut, loss_fn, optimizer, epochs=epochs, log=1)\n",
    "res_18_ut = dl_helper.test(test_dataloader, model_18_ut)\n",
    "acc_18_ut = dl_helper.evaluate_pred(y_test, res_18_ut)\n",
    "print('acc', acc_18_ut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a824bb6-c4ad-439a-bab5-c4fbf1474ea3",
   "metadata": {},
   "source": [
    "### Pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647086d-bf6b-4afd-b1cb-8ba83906db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_18_pt = timm.create_model('resnet18', pretrained=True, num_classes=2)\n",
    "print(model_18_pt.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0101907-3e42-41fa-b192-ca44c6966f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_18_pt.fc.parameters(),\n",
    "                             lr=learning_rate,\n",
    "                             eps=1e-2,\n",
    "                             weight_decay=lambda_l2)  # built-in L2\n",
    "\n",
    "epochs = EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130dcf95-ee5d-480f-8d42-dc29acca094c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_18_pt = dl_helper.train_epochs(train_dataloader, valid_dataloader, model_18_pt, loss_fn, optimizer, epochs=epochs, log=1)\n",
    "res_18_pt = dl_helper.test(test_dataloader, model_18_pt)\n",
    "acc_18_pt = dl_helper.evaluate_pred(y_test, res_18_pt)\n",
    "print('acc', acc_18_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d3821-f4b1-4eb8-b115-e0922139a6b8",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11a7b3a-d48d-4fb9-a72c-a8df2cec62a6",
   "metadata": {},
   "source": [
    "### Not pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a013df-bda9-4a1b-9c2a-2974b7dcc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50_ut = timm.create_model('resnet50', pretrained=False, num_classes=2)\n",
    "print(model_50_ut.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc2204-ddb3-451f-8abf-56df02685cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_50_ut.fc.parameters(),\n",
    "                             lr=learning_rate,\n",
    "                             eps=1e-2,\n",
    "                             weight_decay=lambda_l2)  # built-in L2\n",
    "\n",
    "epochs = EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb4bc6-4066-429f-aa2d-e7436b3fa050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_50_ut = dl_helper.train_epochs(train_dataloader, valid_dataloader, model_50_ut, loss_fn, optimizer, epochs=epochs, log=1)\n",
    "res_50_ut = dl_helper.test(test_dataloader, model_50_ut)\n",
    "acc_50_ut = dl_helper.evaluate_pred(y_test, res_50_ut)\n",
    "print('acc', acc_50_ut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839e11b-8028-4cb5-ba40-41953330b0e9",
   "metadata": {},
   "source": [
    "### Pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a2c3c-8bb2-4d4c-96b9-adaca2db8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50_pt = timm.create_model('resnet50', pretrained=True, num_classes=2)\n",
    "print(model_50_pt.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6a341-1d99-4929-8f2f-051a164326c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_50_pt.fc.parameters(),\n",
    "                             lr=learning_rate,\n",
    "                             eps=1e-2,\n",
    "                             weight_decay=lambda_l2)  # built-in L2\n",
    "\n",
    "epochs = EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d944400-f31f-47ad-9737-08522cfdce09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_50_pt = dl_helper.train_epochs(train_dataloader, valid_dataloader, model_50_pt, loss_fn, optimizer, epochs=epochs, log=1)\n",
    "res_50_pt = dl_helper.test(test_dataloader, model_50_pt)\n",
    "acc_50_pt = dl_helper.evaluate_pred(y_test, res_50_pt)\n",
    "print('acc', acc_50_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a1498-5c79-47b0-8870-f90f2420ec7b",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af94c8-60ef-4c47-b41f-c97a15736685",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy resnet_18 not pretrained :', acc_18_ut)\n",
    "print('Accuracy resnet_18 pretrained     :', acc_18_pt)\n",
    "print('Accuracy resnet_50 not pretrained :', acc_50_ut)\n",
    "print('Accuracy resnet_50 pretrained     :', acc_50_pt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
